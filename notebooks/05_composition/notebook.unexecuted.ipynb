{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning in Julia (continued)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An introduction to the\n",
    "[MLJ](https://alan-turing-institute.github.io/MLJ.jl/stable/)\n",
    "toolbox."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspect Julia version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "VERSION"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following instantiates a package environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The package environment has been created using **Julia 1.6** and may not\n",
    "instantiate properly for other Julia versions."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"env\")\n",
    "Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General resources"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [MLJ Cheatsheet](https://alan-turing-institute.github.io/MLJ.jl/dev/mlj_cheatsheet/)\n",
    "- [Common MLJ Workflows](https://alan-turing-institute.github.io/MLJ.jl/dev/common_mlj_workflows/)\n",
    "- [MLJ manual](https://alan-turing-institute.github.io/MLJ.jl/dev/)\n",
    "- [Data Science Tutorials in Julia](https://juliaai.github.io/DataScienceTutorials.jl/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5 - Advanced Model Composition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Learn how to build a prototypes of a composite model, called a *learning network*\n",
    "> 2. Learn how to use the `@from_network` macro to export a learning network as a new stand-alone model type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipelines are great for composing models in an unbranching\n",
    "sequence. Another built-in type of model composition is a model\n",
    "*stack*; see\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/model_stacking/#Model-Stacking)\n",
    "for details. For other more complicated model compositions you'll want to\n",
    "use MLJ's generic model composition syntax. There are two main\n",
    "steps:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Prototype** the composite model by building a *learning\n",
    "  network*, which can be tested on some (dummy) data as you build\n",
    "  it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Export** the learning network as a new stand-alone model type."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Like pipeline models, instances of the exported model type behave\n",
    "like any other model (and are not bound to any data, until you wrap\n",
    "them in a machine)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a pipeline using the generic composition syntax"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To warm up, we'll do the equivalent of"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "pipe = Standardizer |> LogisticClassifier;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "using the generic syntax."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's some dummy data we'll be using to test our learning network:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = make_blobs(5, 3)\n",
    "pretty(X)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 0** - Proceed as if you were combining the models \"by hand\",\n",
    "using all the data available for training, transforming and\n",
    "prediction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "stand = Standardizer();\n",
    "linear = LogisticClassifier();\n",
    "\n",
    "mach1 = machine(stand, X);\n",
    "fit!(mach1);\n",
    "Xstand = transform(mach1, X);\n",
    "\n",
    "mach2 = machine(linear, Xstand, y);\n",
    "fit!(mach2);\n",
    "yhat = predict(mach2, Xstand)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 1** - Edit your code as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- pre-wrap the data in `Source` nodes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- delete the `fit!` calls"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = source(X)  # or X = source() if not testing\n",
    "y = source(y)  # or y = source()\n",
    "\n",
    "stand = Standardizer();\n",
    "linear = LogisticClassifier();\n",
    "\n",
    "mach1 = machine(stand, X);\n",
    "Xstand = transform(mach1, X);\n",
    "\n",
    "mach2 = machine(linear, Xstand, y);\n",
    "yhat = predict(mach2, Xstand)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `X`, `y`, `Xstand` and `yhat` are *nodes* (\"variables\" or\n",
    "\"dynammic data\") instead of data. All training, predicting and\n",
    "transforming is now executed lazily, whenever we `fit!` one of these\n",
    "nodes. We *call* a node to retrieve the data it represents in the\n",
    "original manual workflow."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(Xstand)\n",
    "Xstand() |> pretty"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(yhat);\n",
    "yhat()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The node `yhat` is the \"descendant\" (in an associated DAG we have\n",
    "defined) of a unique source node:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sources(yhat)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data at the source node is replaced by `Xnew` to obtain a\n",
    "new prediction when we call `yhat` like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xnew, _ = make_blobs(2, 3);\n",
    "yhat(Xnew)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 2** - Export the learning network as a new stand-alone model type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, somewhat paradoxically, we can wrap the whole network in a\n",
    "special machine - called a *learning network machine* - before have\n",
    "defined the new model type. Indeed doing so is a necessary step in\n",
    "the export process, for this machine will tell the export macro:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- what kind of model the composite will be (`Deterministic`,\n",
    "  `Probabilistic` or `Unsupervised`)a"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- which source nodes are input nodes and which are for the target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- which nodes correspond to each operation (`predict`, `transform`,\n",
    "  etc) that we might want to define"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "surrogate = Probabilistic()     # a model with no fields!\n",
    "mach = machine(surrogate, X, y; predict=yhat)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although we have no real need to use it, this machine behaves like\n",
    "you'd expect it to:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xnew, _ = make_blobs(2, 3)\n",
    "fit!(mach)\n",
    "predict(mach, Xnew)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we create a new model type using a Julia `struct` definition\n",
    "appropriately decorated:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network mach begin\n",
    "    mutable struct YourPipe\n",
    "        standardizer = stand\n",
    "        classifier = linear::Probabilistic\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiating and evaluating on some new data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe = YourPipe()\n",
    "X, y = @load_iris;   # built-in data set\n",
    "mach = machine(pipe, X, y)\n",
    "evaluate!(mach, measure=misclassification_rate, operation=predict_mode)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A composite model to average two regressor predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is condensed version of\n",
    "[this](https://github.com/alan-turing-institute/MLJ.jl/blob/master/binder/MLJ_demo.ipynb)\n",
    "tutorial. We will define a composite model that:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- standardizes the input data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- learns and applies a Box-Cox transformation to the target variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- blends the predictions of two supervised learning models - a ridge\n",
    " regressor and a random forest regressor; we'll blend using a simple\n",
    " average (for a more sophisticated stacking example, see\n",
    " [here](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/stacking/))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- applies the *inverse* Box-Cox transformation to this blended prediction"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "RandomForestRegressor = @load RandomForestRegressor pkg=DecisionTree\n",
    "RidgeRegressor = @load RidgeRegressor pkg=MLJLinearModels"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Input layer**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = source()\n",
    "y = source()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First layer and target transformation**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "std_model = Standardizer()\n",
    "stand = machine(std_model, X)\n",
    "W = MLJ.transform(stand, X)\n",
    "\n",
    "box_model = UnivariateBoxCoxTransformer()\n",
    "box = machine(box_model, y)\n",
    "z = MLJ.transform(box, y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Second layer**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ridge_model = RidgeRegressor(lambda=0.1)\n",
    "ridge = machine(ridge_model, W, z)\n",
    "\n",
    "forest_model = RandomForestRegressor(n_trees=50)\n",
    "forest = machine(forest_model, W, z)\n",
    "\n",
    "ẑ = 0.5*predict(ridge, W) + 0.5*predict(forest, W)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Output**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = inverse_transform(box, ẑ)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the learning network defined, we're ready to export:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network machine(Deterministic(), X, y, predict=ŷ) begin\n",
    "    mutable struct CompositeModel\n",
    "        rgs1 = ridge_model\n",
    "        rgs2 = forest_model\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's instantiate the new model type and try it out on some data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "composite = CompositeModel()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = @load_boston;\n",
    "mach = machine(composite, X, y);\n",
    "evaluate!(mach,\n",
    "          resampling=CV(nfolds=6, shuffle=true),\n",
    "          measures=[rms, mae])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 5\n",
    "\n",
    "- From the MLJ manual:\n",
    "   - [Learning Networks](https://alan-turing-institute.github.io/MLJ.jl/stable/composing_models/#Learning-Networks-1)\n",
    "- From Data Science Tutorials:\n",
    "    - [Learning Networks](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/learning-networks/)\n",
    "    - [Learning Networks 2](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/learning-networks-2/)\n",
    "    - [Stacking](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/stacking/): an advanced example of model composition\n",
    "    - [Finer Control](https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Method-II:-Finer-control-(advanced)-1):\n",
    "      exporting learning networks without a macro for finer control"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='solutions-to-exercises'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
