{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning in Julia (conclusion)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An introduction to the\n",
    "[MLJ](https://alan-turing-institute.github.io/MLJ.jl/stable/)\n",
    "toolbox."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspect Julia version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "VERSION"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following instantiates a package environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The package environment has been created using **Julia 1.6** and may not\n",
    "instantiate properly for other Julia versions."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"env\")\n",
    "Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General resources"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [MLJ Cheatsheet](https://alan-turing-institute.github.io/MLJ.jl/dev/mlj_cheatsheet/)\n",
    "- [Common MLJ Workflows](https://alan-turing-institute.github.io/MLJ.jl/dev/common_mlj_workflows/)\n",
    "- [MLJ manual](https://alan-turing-institute.github.io/MLJ.jl/dev/)\n",
    "- [Data Science Tutorials in Julia](https://juliaai.github.io/DataScienceTutorials.jl/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solutions to exercises"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ, UrlDownload, CSV, DataFrames, Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the question statememt:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "quality = [\"good\", \"poor\", \"poor\", \"excellent\", missing, \"good\", \"excellent\"]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "quality = coerce(quality, OrderedFactor);\n",
    "levels!(quality, [\"poor\", \"good\", \"excellent\"]);\n",
    "elscitype(quality)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the question statement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "house_csv = urldownload(\"https://raw.githubusercontent.com/ablaom/\"*\n",
    "                        \"MachineLearningInJulia2020/for-MLJ-version-0.16/\"*\n",
    "                        \"data/house.csv\");\n",
    "house = DataFrames.DataFrame(house_csv)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "First pass:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, autotype(house));\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the \"sqft\" fields refer to \"square feet\" so are\n",
    "really `Continuous`. We'll regard `:yr_built` (the other `Count`\n",
    "variable above) as `Continuous` as well. So:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, Count => Continuous);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And `:zipcode` should not be ordered:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, :zipcode => Multiclass);\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`:bathrooms` looks like it has a lot of levels, but on further\n",
    "inspection we see why, and `OrderedFactor` remains appropriate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import StatsBase.countmap\n",
    "countmap(house.bathrooms)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 4 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the question statement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Distributions\n",
    "poisson = Distributions.Poisson\n",
    "\n",
    "age = 18 .+ 60*rand(10);\n",
    "salary = coerce(rand([\"small\", \"big\", \"huge\"], 10), OrderedFactor);\n",
    "levels!(salary, [\"small\", \"big\", \"huge\"]);\n",
    "small = salary[1]\n",
    "\n",
    "X4 = DataFrames.DataFrame(age=age, salary=salary)\n",
    "\n",
    "n_devices(salary) = salary > small ? rand(poisson(1.3)) : rand(poisson(2.9))\n",
    "y4 = [n_devices(row.salary) for row in eachrow(X4)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "4(a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are *no* models that apply immediately:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(matching(X4, y4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "4(b)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y4 = coerce(y4, Continuous);\n",
    "models(matching(X4, y4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 6 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the question statement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using UrlDownload, CSV\n",
    "csv_file = urldownload(\"https://raw.githubusercontent.com/ablaom/\"*\n",
    "                   \"MachineLearningInJulia2020/\"*\n",
    "                   \"for-MLJ-version-0.16/data/horse.csv\");\n",
    "horse = DataFrames.DataFrame(csv_file); # convert to data frame\n",
    "coerce!(horse, autotype(horse));\n",
    "coerce!(horse, Count => Continuous);\n",
    "coerce!(horse,\n",
    "        :surgery               => Multiclass,\n",
    "        :age                   => Multiclass,\n",
    "        :mucous_membranes      => Multiclass,\n",
    "        :capillary_refill_time => Multiclass,\n",
    "        :outcome               => Multiclass,\n",
    "        :cp_data               => Multiclass);\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(horse,\n",
    "              ==(:outcome),\n",
    "              name -> elscitype(Tables.getcolumn(horse, name)) == Continuous);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(i)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.7)\n",
    "model = (@load LogisticClassifier pkg=MLJLinearModels)();\n",
    "model.lambda = 100\n",
    "mach = machine(model, X, y)\n",
    "fit!(mach, rows=train)\n",
    "fitted_params(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coefs_given_feature = Dict(fitted_params(mach).coefs)\n",
    "coefs_given_feature[:pulse]\n",
    "\n",
    "#6(b)(ii)\n",
    "\n",
    "yhat = predict(mach, rows=test); # or predict(mach, X[test,:])\n",
    "err = cross_entropy(yhat, y[test]) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(iii)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predicted probabilities of the actual observations in the test\n",
    "are given by"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = broadcast(pdf, yhat, y[test]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of times this probability exceeds 50% is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n50 = filter(x -> x > 0.5, p) |> length"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, as a proportion:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n50/length(test)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(iv)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "misclassification_rate(mode.(yhat), y[test])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(i)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = (@load RandomForestClassifier pkg=DecisionTree)()\n",
    "mach = machine(model, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6), measure=cross_entropy)\n",
    "\n",
    "r = range(model, :n_trees, lower=10, upper=70, scale=:log10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since random forests are inherently randomized, we generate multiple\n",
    "curves:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plt = plot()\n",
    "for i in 1:4\n",
    "    one_curve = learning_curve(mach,\n",
    "                           range=r,\n",
    "                           resampling=Holdout(),\n",
    "                           measure=cross_entropy)\n",
    "    plot!(one_curve.parameter_values, one_curve.measurements)\n",
    "end\n",
    "xlabel!(plt, \"n_trees\")\n",
    "ylabel!(plt, \"cross entropy\")\n",
    "savefig(\"exercise_6ci.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(ii)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=CV(nfolds=9),\n",
    "                measure=cross_entropy,\n",
    "                rows=train).measurement[1]\n",
    "\n",
    "model.n_trees = 90"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(iii)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "err_forest = evaluate!(mach, resampling=Holdout(),\n",
    "                       measure=cross_entropy).measurement[1]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 7"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "KMeans = @load KMeans pkg=Clustering\n",
    "EvoTreeClassifier = @load EvoTreeClassifier\n",
    "pipe = Standardizer |>\n",
    "    ContinuousEncoder |>\n",
    "    KMeans(k=10) |>\n",
    "    EvoTreeClassifier(nrounds=50)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6), measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(pipe, :(evo_tree_classifier.max_depth), lower=1, upper=10)\n",
    "\n",
    "curve = learning_curve(mach,\n",
    "                       range=r,\n",
    "                       resampling=CV(nfolds=6),\n",
    "                       measure=cross_entropy)\n",
    "\n",
    "plt = plot(curve.parameter_values, curve.measurements)\n",
    "xlabel!(plt, \"max_depth\")\n",
    "ylabel!(plt, \"CV estimate of cross entropy\")\n",
    "savefig(\"exercise_7c.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a second curve using a different random seed for the booster:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random\n",
    "pipe.evo_tree_classifier.rng = MersenneTwister(123)\n",
    "curve = learning_curve(mach,\n",
    "                       range=r,\n",
    "                       resampling=CV(nfolds=6),\n",
    "                       measure=cross_entropy)\n",
    "plot!(curve.parameter_values, curve.measurements)\n",
    "savefig(\"exercise_7c_2.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "One can automate the production of multiple curves with different\n",
    "seeds in the following way:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "curves = learning_curve(mach,\n",
    "                        range=r,\n",
    "                        resampling=CV(nfolds=6),\n",
    "                        measure=cross_entropy,\n",
    "                        rng_name=:(evo_tree_classifier.rng),\n",
    "                        rngs=6) # list of RNGs, or num to auto generate\n",
    "plt = plot(curves.parameter_values, curves.measurements)\n",
    "savefig(\"exercise_7c_3.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have multiple threads available in your julia session, you\n",
    "can add the option `acceleration=CPUThreads()` to speed up this\n",
    "computation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the question statement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(house, ==(:price), rng=123); # from Exercise 3\n",
    "\n",
    "EvoTreeRegressor = @load EvoTreeRegressor\n",
    "tree_booster = EvoTreeRegressor(nrounds = 70)\n",
    "model = ContinuousEncoder |> tree_booster\n",
    "\n",
    "r2 = range(model,\n",
    "           :(evo_tree_regressor.nbins),\n",
    "           lower = 2.5,\n",
    "           upper= 7.5, scale=x->2^round(Int, x))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r1 = range(model, :(evo_tree_regressor.max_depth), lower=1, upper=12)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_model = TunedModel(model=model,\n",
    "                         ranges=[r1, r2],\n",
    "                         resampling=Holdout(),\n",
    "                         measures=mae,\n",
    "                         tuning=RandomSearch(rng=123),\n",
    "                         n=40)\n",
    "\n",
    "tuned_mach = machine(tuned_model, X, y) |> fit!\n",
    "plt = plot(tuned_mach)\n",
    "savefig(\"exercise_8c.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "best_model = report(tuned_mach).best_model;\n",
    "best_mach = machine(best_model, X, y);\n",
    "best_err = evaluate!(best_mach, resampling=CV(nfolds=3), measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_err = evaluate!(tuned_mach, resampling=CV(nfolds=3), measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
