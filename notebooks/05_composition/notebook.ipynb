{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning in Julia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An introduction to the\n",
    "[MLJ](https://alan-turing-institute.github.io/MLJ.jl/stable/)\n",
    "toolbox."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspect Julia version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "v\"1.6.3\""
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "VERSION"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following instantiates a package environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The package environment has been created using **Julia 1.6** and may not\n",
    "instantiate properly for other Julia versions."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activating environment at `~/GoogleDrive/Julia/MLJ/MLJTutorial/notebooks/05_composition/env/Project.toml`\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"env\")\n",
    "Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General resources"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [MLJ Cheatsheet](https://alan-turing-institute.github.io/MLJ.jl/dev/mlj_cheatsheet/)\n",
    "- [Common MLJ Workflows](https://alan-turing-institute.github.io/MLJ.jl/dev/common_mlj_workflows/)\n",
    "- [MLJ manual](https://alan-turing-institute.github.io/MLJ.jl/dev/)\n",
    "- [Data Science Tutorials in Julia](https://juliaai.github.io/DataScienceTutorials.jl/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5 - Advanced Model Composition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Learn how to build a prototypes of a composite model, called a *learning network*\n",
    "> 2. Learn how to use the `@from_network` macro to export a learning network as a new stand-alone model type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`@pipeline` is great for composing models in an unbranching\n",
    "sequence. Another built-in type of model composition is a model\n",
    "*stack*; see\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/model_stacking/#Model-Stacking)\n",
    "for details. For other complicated model compositions you'll want to\n",
    "use MLJ's generic model composition syntax. There are two main\n",
    "steps:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Prototype** the composite model by building a *learning\n",
    "  network*, which can be tested on some (dummy) data as you build\n",
    "  it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Export** the learning network as a new stand-alone model type."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Like pipeline models, instances of the exported model type behave\n",
    "like any other model (and are not bound to any data, until you wrap\n",
    "them in a machine)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a pipeline using the generic composition syntax"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To warm up, we'll do the equivalent of"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJLinearModels ✔\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "pipe = @pipeline Standardizer LogisticClassifier;"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "using the generic syntax."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's some dummy data we'll be using to test our learning network:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┬────────────┬────────────┐\n",
      "│ x1         │ x2         │ x3         │\n",
      "│ Float64    │ Float64    │ Float64    │\n",
      "│ Continuous │ Continuous │ Continuous │\n",
      "├────────────┼────────────┼────────────┤\n",
      "│ 2.53013    │ -1.89957   │ 5.54883    │\n",
      "│ 0.291037   │ -1.67608   │ 3.07317    │\n",
      "│ -3.91176   │ -1.47851   │ 11.7301    │\n",
      "│ -1.01752   │ 8.28512    │ 7.01315    │\n",
      "│ 2.8618     │ -2.03601   │ 3.03607    │\n",
      "└────────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "X, y = make_blobs(5, 3)\n",
    "pretty(X)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 0** - Proceed as if you were combining the models \"by hand\",\n",
    "using all the data available for training, transforming and\n",
    "prediction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Training Machine{Standardizer,…}.\n",
      "[ Info: Training Machine{LogisticClassifier,…}.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5-element MLJBase.UnivariateFiniteVector{ScientificTypesBase.Multiclass{3}, Int64, UInt32, Float64}:\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.0671, 2=>0.0688, 3=>0.864)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.0781, 2=>0.0733, 3=>0.849)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.128, 2=>0.714, 3=>0.158)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.658, 2=>0.136, 3=>0.206)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.0449, 2=>0.0317, 3=>0.923)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "stand = Standardizer();\n",
    "linear = LogisticClassifier();\n",
    "\n",
    "mach1 = machine(stand, X);\n",
    "fit!(mach1);\n",
    "Xstand = transform(mach1, X);\n",
    "\n",
    "mach2 = machine(linear, Xstand, y);\n",
    "fit!(mach2);\n",
    "yhat = predict(mach2, Xstand)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 1** - Edit your code as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- pre-wrap the data in `Source` nodes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- delete the `fit!` calls"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Node{Machine{LogisticClassifier,…}}\n  args:\n    1:\tNode{Machine{Standardizer,…}}\n  formula:\n    predict(\n        \u001b[0m\u001b[1mMachine{LogisticClassifier,…}\u001b[22m, \n        transform(\n            \u001b[0m\u001b[1mMachine{Standardizer,…}\u001b[22m, \n            Source @873))"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "X = source(X)  # or X = source() if not testing\n",
    "y = source(y)  # or y = source()\n",
    "\n",
    "stand = Standardizer();\n",
    "linear = LogisticClassifier();\n",
    "\n",
    "mach1 = machine(stand, X);\n",
    "Xstand = transform(mach1, X);\n",
    "\n",
    "mach2 = machine(linear, Xstand, y);\n",
    "yhat = predict(mach2, Xstand)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `X`, `y`, `Xstand` and `yhat` are *nodes* (\"variables\" or\n",
    "\"dynammic data\") instead of data. All training, predicting and\n",
    "transforming is now executed lazily, whenever we `fit!` one of these\n",
    "nodes. We *call* a node to retrieve the data it represents in the\n",
    "original manual workflow."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Training Machine{Standardizer,…}.\n",
      "┌────────────┬────────────┬────────────┐\n",
      "│ x1         │ x2         │ x3         │\n",
      "│ Float64    │ Float64    │ Float64    │\n",
      "│ Continuous │ Continuous │ Continuous │\n",
      "├────────────┼────────────┼────────────┤\n",
      "│ 0.856089   │ -0.474923  │ -0.148276  │\n",
      "│ 0.0504786  │ -0.425292  │ -0.839008  │\n",
      "│ -1.46166   │ -0.381415  │ 1.57636    │\n",
      "│ -0.420332  │ 1.78685    │ 0.260282   │\n",
      "│ 0.975421   │ -0.505224  │ -0.84936   │\n",
      "└────────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "fit!(Xstand)\n",
    "Xstand() |> pretty"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Not retraining Machine{Standardizer,…}. Use `force=true` to force.\n",
      "[ Info: Training Machine{LogisticClassifier,…}.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5-element MLJBase.UnivariateFiniteVector{ScientificTypesBase.Multiclass{3}, Int64, UInt32, Float64}:\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.0671, 2=>0.0688, 3=>0.864)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.0781, 2=>0.0733, 3=>0.849)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.128, 2=>0.714, 3=>0.158)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.658, 2=>0.136, 3=>0.206)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.0449, 2=>0.0317, 3=>0.923)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "fit!(yhat);\n",
    "yhat()"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "The node `yhat` is the \"descendant\" (in an associated DAG we have\n",
    "defined) of a unique source node:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element Vector{Any}:\n Source @873 ⏎ `ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}`\n Source @119 ⏎ `AbstractVector{ScientificTypesBase.Multiclass{3}}`"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "sources(yhat)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data at the source node is replaced by `Xnew` to obtain a\n",
    "new prediction when we call `yhat` like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element MLJBase.UnivariateFiniteVector{ScientificTypesBase.Multiclass{3}, Int64, UInt32, Float64}:\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.057, 2=>0.000505, 3=>0.942)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.00281, 2=>1.31e-5, 3=>0.997)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "Xnew, _ = make_blobs(2, 3);\n",
    "yhat(Xnew)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 2** - Export the learning network as a new stand-alone model type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, somewhat paradoxically, we can wrap the whole network in a\n",
    "special machine - called a *learning network machine* - before have\n",
    "defined the new model type. Indeed doing so is a necessary step in\n",
    "the export process, for this machine will tell the export macro:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- what kind of model the composite will be (`Deterministic`,\n",
    "  `Probabilistic` or `Unsupervised`)a"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- which source nodes are input nodes and which are for the target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- which nodes correspond to each operation (`predict`, `transform`,\n",
    "  etc) that we might want to define"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Machine{ProbabilisticSurrogate,…} trained 0 times; does not cache data\n  args: \n    1:\tSource @873 ⏎ `ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}`\n    2:\tSource @119 ⏎ `AbstractVector{ScientificTypesBase.Multiclass{3}}`\n"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "surrogate = Probabilistic()     # a model with no fields!\n",
    "mach = machine(surrogate, X, y; predict=yhat)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although we have no real need to use it, this machine behaves like\n",
    "you'd expect it to:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Not retraining Machine{Standardizer,…}. Use `force=true` to force.\n",
      "[ Info: Not retraining Machine{LogisticClassifier,…}. Use `force=true` to force.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element MLJBase.UnivariateFiniteVector{ScientificTypesBase.Multiclass{3}, Int64, UInt32, Float64}:\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.00935, 2=>0.169, 3=>0.822)\n UnivariateFinite{ScientificTypesBase.Multiclass{3}}(1=>0.00551, 2=>0.0161, 3=>0.978)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "Xnew, _ = make_blobs(2, 3)\n",
    "fit!(mach)\n",
    "predict(mach, Xnew)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we create a new model type using a Julia `struct` definition\n",
    "appropriately decorated:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network mach begin\n",
    "    mutable struct YourPipe\n",
    "        standardizer = stand\n",
    "        classifier = linear::Probabilistic\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiating and evaluating on some new data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PerformanceEvaluation object with these fields:\n  measure, measurement, operation, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_pairs\nExtract:\n┌─────────────────────────┬─────────────┬──────────────┬────────────────────────\n│\u001b[22m measure                 \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m per_fold             \u001b[0m ⋯\n├─────────────────────────┼─────────────┼──────────────┼────────────────────────\n│ MisclassificationRate() │ 0.08        │ predict_mode │ [0.0, 0.04, 0.08, 0.0 ⋯\n└─────────────────────────┴─────────────┴──────────────┴────────────────────────\n\u001b[36m                                                                1 column omitted\u001b[0m\n"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "pipe = YourPipe()\n",
    "X, y = @load_iris;   # built-in data set\n",
    "mach = machine(pipe, X, y)\n",
    "evaluate!(mach, measure=misclassification_rate, operation=predict_mode)"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A composite model to average two regressor predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is condensed version of\n",
    "[this](https://github.com/alan-turing-institute/MLJ.jl/blob/master/binder/MLJ_demo.ipynb)\n",
    "tutorial. We will define a composite model that:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- standardizes the input data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- learns and applies a Box-Cox transformation to the target variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- blends the predictions of two supervised learning models - a ridge\n",
    " regressor and a random forest regressor; we'll blend using a simple\n",
    " average (for a more sophisticated stacking example, see\n",
    " [here](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/stacking/))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- applies the *inverse* Box-Cox transformation to this blended prediction"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJDecisionTreeInterface ✔\n",
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJLinearModels ✔\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLJLinearModels.RidgeRegressor"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "RandomForestRegressor = @load RandomForestRegressor pkg=DecisionTree\n",
    "RidgeRegressor = @load RidgeRegressor pkg=MLJLinearModels"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Input layer**"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Source @764 ⏎ `Nothing`"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "X = source()\n",
    "y = source()"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First layer and target transformation**"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Node{Machine{UnivariateBoxCoxTransformer,…}}\n  args:\n    1:\tSource @764\n  formula:\n    transform(\n        \u001b[0m\u001b[1mMachine{UnivariateBoxCoxTransformer,…}\u001b[22m, \n        Source @764)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "std_model = Standardizer()\n",
    "stand = machine(std_model, X)\n",
    "W = MLJ.transform(stand, X)\n",
    "\n",
    "box_model = UnivariateBoxCoxTransformer()\n",
    "box = machine(box_model, y)\n",
    "z = MLJ.transform(box, y)"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Second layer**"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Node{Nothing}\n  args:\n    1:\tNode{Nothing}\n    2:\tNode{Nothing}\n  formula:\n    +(\n        #134(\n            predict(\n                \u001b[0m\u001b[1mMachine{RidgeRegressor,…}\u001b[22m, \n                transform(\n                    \u001b[0m\u001b[1mMachine{Standardizer,…}\u001b[22m, \n                    Source @518))),\n        #134(\n            predict(\n                \u001b[0m\u001b[1mMachine{RandomForestRegressor,…}\u001b[22m, \n                transform(\n                    \u001b[0m\u001b[1mMachine{Standardizer,…}\u001b[22m, \n                    Source @518))))"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "ridge_model = RidgeRegressor(lambda=0.1)\n",
    "ridge = machine(ridge_model, W, z)\n",
    "\n",
    "forest_model = RandomForestRegressor(n_trees=50)\n",
    "forest = machine(forest_model, W, z)\n",
    "\n",
    "ẑ = 0.5*predict(ridge, W) + 0.5*predict(forest, W)"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Output**"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Node{Machine{UnivariateBoxCoxTransformer,…}}\n  args:\n    1:\tNode{Nothing}\n  formula:\n    inverse_transform(\n        \u001b[0m\u001b[1mMachine{UnivariateBoxCoxTransformer,…}\u001b[22m, \n        +(\n            #134(\n                predict(\n                    \u001b[0m\u001b[1mMachine{RidgeRegressor,…}\u001b[22m, \n                    transform(\n                        \u001b[0m\u001b[1mMachine{Standardizer,…}\u001b[22m, \n                        Source @518))),\n            #134(\n                predict(\n                    \u001b[0m\u001b[1mMachine{RandomForestRegressor,…}\u001b[22m, \n                    transform(\n                        \u001b[0m\u001b[1mMachine{Standardizer,…}\u001b[22m, \n                        Source @518)))))"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "ŷ = inverse_transform(box, ẑ)"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the learning network defined, we're ready to export:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network machine(Deterministic(), X, y, predict=ŷ) begin\n",
    "    mutable struct CompositeModel\n",
    "        rgs1 = ridge_model\n",
    "        rgs2 = forest_model\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's instantiate the new model type and try it out on some data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CompositeModel(\n    rgs1 = RidgeRegressor(\n            lambda = 0.1,\n            fit_intercept = true,\n            penalize_intercept = false,\n            solver = nothing),\n    rgs2 = RandomForestRegressor(\n            max_depth = -1,\n            min_samples_leaf = 1,\n            min_samples_split = 2,\n            min_purity_increase = 0.0,\n            n_subfeatures = -1,\n            n_trees = 50,\n            sampling_fraction = 0.7,\n            pdf_smoothing = 0.0,\n            rng = Random._GLOBAL_RNG()))"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "cell_type": "code",
   "source": [
    "composite = CompositeModel()"
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:36\u001b[K\rEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:18\u001b[K\rEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:09\u001b[K\rEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:04\u001b[K\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:18\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PerformanceEvaluation object with these fields:\n  measure, measurement, operation, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_pairs\nExtract:\n┌────────────────────────┬─────────────┬───────────┬────────────────────────────\n│\u001b[22m measure                \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m operation \u001b[0m│\u001b[22m per_fold                 \u001b[0m ⋯\n├────────────────────────┼─────────────┼───────────┼────────────────────────────\n│ RootMeanSquaredError() │ 3.76        │ predict   │ [2.9, 4.98, 3.72, 3.71, 2 ⋯\n│ MeanAbsoluteError()    │ 2.42        │ predict   │ [2.1, 2.93, 2.37, 2.47, 2 ⋯\n└────────────────────────┴─────────────┴───────────┴────────────────────────────\n\u001b[36m                                                                1 column omitted\u001b[0m\n"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "cell_type": "code",
   "source": [
    "X, y = @load_boston;\n",
    "mach = machine(composite, X, y);\n",
    "evaluate!(mach,\n",
    "          resampling=CV(nfolds=6, shuffle=true),\n",
    "          measures=[rms, mae])"
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 5\n",
    "\n",
    "- From the MLJ manual:\n",
    "   - [Learning Networks](https://alan-turing-institute.github.io/MLJ.jl/stable/composing_models/#Learning-Networks-1)\n",
    "- From Data Science Tutorials:\n",
    "    - [Learning Networks](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/learning-networks/)\n",
    "    - [Learning Networks 2](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/learning-networks-2/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    - [Stacking](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/stacking/): an advanced example of model composition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    - [Finer Control](https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Method-II:-Finer-control-(advanced)-1):\n",
    "      exporting learning networks without a macro for finer control"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='solutions-to-exercises'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
